"""
Knowledge Retriever Service
===========================
Retrieves relevant knowledge from the extracted knowledge base using
keyword search and relevance scoring.
"""

import json
import re
from pathlib import Path
from typing import List, Dict, Any, Optional
import logging
from difflib import SequenceMatcher

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class KnowledgeRetriever:
    """
    Retrieves relevant knowledge chunks using keyword search and relevance scoring.
    This implementation uses keyword matching instead of embeddings for simplicity.
    """
    
    def __init__(self, knowledge_file: str = None):
        """
        Initialize the knowledge retriever.
        
        Args:
            knowledge_file: Path to the knowledge base JSON file
        """
        if knowledge_file is None:
            knowledge_file = Path(__file__).parent.parent / "knowledge_base.json"
        
        self.knowledge_base = self._load_knowledge_base(knowledge_file)
        logger.info(f"Loaded {len(self.knowledge_base)} knowledge chunks")
        
    def _load_knowledge_base(self, knowledge_file: Path) -> List[Dict[str, Any]]:
        """Load the knowledge base from JSON file."""
        try:
            with open(knowledge_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            logger.warning(f"Knowledge base not found at {knowledge_file}")
            return []
        except Exception as e:
            logger.error(f"Failed to load knowledge base: {e}")
            return []
    
    def _calculate_relevance_score(self, query: str, chunk: Dict[str, Any]) -> float:
        """
        Calculate relevance score between query and chunk.
        
        Uses a combination of:
        - Keyword matching
        - Topic matching
        - Text similarity
        """
        query_lower = query.lower()
        chunk_text_lower = chunk.get("text", "").lower()
        chunk_topic = chunk.get("topic", "").lower()
        
        score = 0.0
        
        # Extract important keywords from query
        query_words = set(re.findall(r'\b\w+\b', query_lower))
        chunk_words = set(re.findall(r'\b\w+\b', chunk_text_lower))
        
        # Keyword overlap score (0-40 points)
        if query_words:
            overlap = len(query_words & chunk_words)
            keyword_score = (overlap / len(query_words)) * 40
            score += keyword_score
        
        # Topic match bonus (0-30 points)
        if chunk_topic:
            topic_words = set(chunk_topic.split('_'))
            topic_overlap = len(query_words & topic_words)
            if topic_overlap > 0:
                score += 30
        
        # Pattern-specific keywords bonus (0-20 points)
        pattern_keywords = {
            "engulfing": ["engulfing", "bullish", "bearish", "reversal"],
            "doji": ["doji", "indecision", "star", "hammer"],
            "support": ["support", "resistance", "level", "bounce"],
            "breakout": ["breakout", "breakdown", "volume", "confirmation"],
            "triangle": ["triangle", "ascending", "descending", "symmetrical"],
            "double": ["double", "top", "bottom", "reversal"],
            "head": ["head", "shoulders", "neckline"],
            "macd": ["macd", "signal", "histogram", "convergence"],
            "rsi": ["rsi", "overbought", "oversold", "momentum"],
            "moving": ["moving", "average", "ma", "sma", "ema", "cross"]
        }
        
        for pattern_type, keywords in pattern_keywords.items():
            if any(keyword in query_lower for keyword in keywords):
                if any(keyword in chunk_text_lower for keyword in keywords):
                    score += 20
                    break
        
        # Text similarity score (0-10 points)
        # Use sequence matching for partial text similarity
        if len(query) > 10 and len(chunk_text_lower) > 10:
            similarity = SequenceMatcher(None, query_lower[:200], chunk_text_lower[:200]).ratio()
            score += similarity * 10
        
        # Source quality bonus
        quality_sources = ["Encyclopedia of Chart Patterns", "Technical Analysis for Dummies"]
        if any(source in chunk.get("source", "") for source in quality_sources):
            score *= 1.1
        
        return score
    
    def search_knowledge(self, query: str, top_k: int = 3, min_score: float = 10.0) -> List[Dict[str, Any]]:
        """
        Search for relevant knowledge chunks.
        
        Args:
            query: Search query
            top_k: Number of top results to return
            min_score: Minimum relevance score threshold
            
        Returns:
            List of relevant knowledge chunks with scores
        """
        if not self.knowledge_base:
            return []
        
        # Calculate relevance scores for all chunks
        scored_chunks = []
        for chunk in self.knowledge_base:
            score = self._calculate_relevance_score(query, chunk)
            if score >= min_score:
                scored_chunks.append({
                    **chunk,
                    "relevance_score": score
                })
        
        # Sort by relevance score
        scored_chunks.sort(key=lambda x: x["relevance_score"], reverse=True)
        
        # Return top k results
        results = scored_chunks[:top_k]
        
        if results:
            logger.info(f"Found {len(results)} relevant chunks for query: '{query[:50]}...'")
            logger.info(f"Top result score: {results[0]['relevance_score']:.2f}")
        
        return results
    
    def get_pattern_knowledge(self, pattern_type: str) -> List[Dict[str, Any]]:
        """
        Get specific knowledge about a pattern type.
        
        Args:
            pattern_type: Type of pattern (e.g., "bullish_engulfing", "double_bottom")
            
        Returns:
            List of relevant chunks about the pattern
        """
        # Convert pattern type to search query
        pattern_query = pattern_type.replace("_", " ")
        
        # Search for pattern-specific knowledge
        results = self.search_knowledge(pattern_query, top_k=2, min_score=15.0)
        
        # Filter for high-quality pattern descriptions
        pattern_results = []
        for result in results:
            if pattern_type.lower() in result.get("topic", "").lower():
                pattern_results.append(result)
            elif pattern_query.lower() in result.get("text", "").lower()[:500]:
                pattern_results.append(result)
        
        return pattern_results if pattern_results else results
    
    def get_indicator_knowledge(self, indicator: str, value: float = None) -> List[Dict[str, Any]]:
        """
        Get knowledge about a specific indicator.
        
        Args:
            indicator: Indicator name (e.g., "RSI", "MACD")
            value: Optional indicator value for context-specific search
            
        Returns:
            List of relevant chunks about the indicator
        """
        # Build query based on indicator and value
        query = indicator
        
        if value is not None:
            if indicator.upper() == "RSI":
                if value > 70:
                    query += " overbought"
                elif value < 30:
                    query += " oversold"
                else:
                    query += " neutral"
            elif indicator.upper() == "MACD":
                query += " signal cross"
        
        return self.search_knowledge(query, top_k=2, min_score=15.0)
    
    def get_strategy_knowledge(self, market_condition: str) -> List[Dict[str, Any]]:
        """
        Get trading strategy knowledge for specific market conditions.
        
        Args:
            market_condition: Market condition (e.g., "trending", "ranging", "volatile")
            
        Returns:
            List of relevant strategy chunks
        """
        # Build query for strategy search
        query = f"{market_condition} market strategy trading approach risk management"
        
        results = self.search_knowledge(query, top_k=3, min_score=10.0)
        
        # Filter for strategy-specific content
        strategy_results = []
        for result in results:
            if "strategy" in result.get("topic", "") or "risk" in result.get("topic", ""):
                strategy_results.append(result)
        
        return strategy_results if strategy_results else results[:1]
    
    def format_knowledge_for_agent(self, chunks: List[Dict[str, Any]]) -> str:
        """
        Format knowledge chunks into a string for agent consumption.
        
        Args:
            chunks: List of knowledge chunks
            
        Returns:
            Formatted string with citations
        """
        if not chunks:
            return ""
        
        formatted_parts = []
        for i, chunk in enumerate(chunks[:3], 1):  # Limit to 3 chunks
            source = chunk.get("source", "Unknown")
            page = chunk.get("page", "")
            text = chunk.get("text", "")[:500]  # Truncate long texts
            
            # Clean up text
            text = re.sub(r'\s+', ' ', text).strip()
            
            citation = f"[{i}. {source}"
            if page:
                citation += f", p.{page}"
            citation += "]"
            
            formatted_parts.append(f"{citation}\n{text}")
        
        return "\n\n".join(formatted_parts)


# Example usage
if __name__ == "__main__":
    retriever = KnowledgeRetriever()
    
    # Test pattern search
    print("\n=== Testing Pattern Search ===")
    results = retriever.get_pattern_knowledge("bullish_engulfing")
    for r in results:
        print(f"Score: {r.get('relevance_score', 0):.2f} - Topic: {r['topic']} - Source: {r['source']}")
    
    # Test indicator search
    print("\n=== Testing Indicator Search ===")
    results = retriever.get_indicator_knowledge("RSI", 75)
    for r in results:
        print(f"Score: {r.get('relevance_score', 0):.2f} - Topic: {r['topic']} - Source: {r['source']}")
    
    # Test general search
    print("\n=== Testing General Search ===")
    results = retriever.search_knowledge("how to identify support and resistance levels")
    for r in results:
        print(f"Score: {r.get('relevance_score', 0):.2f} - Topic: {r['topic']} - Source: {r['source']}")